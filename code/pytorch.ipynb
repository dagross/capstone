{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glebradchenko/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os # need for file enumeration\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# CNN\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2,MobileNet,VGG19\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "\n",
    "from tensorflow.keras import utils,losses\n",
    "import tensorflow as tf\n",
    "\n",
    "# some more image preprocessing\n",
    "from tensorflow.keras.layers import RandomBrightness, RandomContrast, RandomCrop, RandomFlip\n",
    "from tensorflow.keras.layers import RandomHeight, RandomRotation, RandomTranslation\n",
    "from tensorflow.keras.layers import RandomWidth, RandomZoom\n",
    "import skimage\n",
    "import cv2\n",
    "from PIL.ExifTags import TAGS\n",
    "from PIL import ExifTags\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "# pre-trained\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import plot_confusion_matrix,ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import skimage.io as io\n",
    "import skimage.transform as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haroun import Data, Model, ConvPool\n",
    "from haroun.augmentation import augmentation\n",
    "from haroun.losses import rmse\n",
    "def load_data():\n",
    "    path =  \"./data/real_and_fake_face/\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for directory in os.listdir(path):\n",
    "        data_path = path + directory\n",
    "        if directory!=\".DS_Store\":\n",
    "\n",
    "            for im in os.listdir(data_path)[:]:\n",
    "                image = io.imread(f\"{data_path}/{im}\")\n",
    "                image = tf.resize(image, (64, 64))\n",
    "                images.append(image)\n",
    "                if directory == \"training_fake\":\n",
    "                    labels.append(\"fake\")\n",
    "                elif directory == \"training_real\":\n",
    "                    labels.append(\"real\")\n",
    "    \n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # images, labels = augmentation(images, labels, flip_y=True, flip_x=True, brightness=True)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'real': 0, 'fake': 1}\n",
    "data = Data(loader=load_data(), classes=classes)\n",
    "data.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data.dataset(split_size=0.05, shuffle=True, random_state=42,\n",
    "             images_format=torch.float32, labels_format=torch.float32,\n",
    "             permute=True, one_hot=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.input_norm = torch.nn.BatchNorm2d(3, affine=False)\n",
    "        self.layer1 = ConvPool(in_features=3, out_features=8)\n",
    "        self.layer2 = ConvPool(in_features=8, out_features=16)\n",
    "        self.layer3 = ConvPool(in_features=16, out_features=32)\n",
    "        self.layer4 = ConvPool(in_features=32, out_features=64)\n",
    "        self.layer5 = ConvPool(in_features=64, out_features=128)\n",
    "        self.layer6 = ConvPool(in_features=128, out_features=256)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.net = torch.nn.Sequential(self.layer1, self.layer2, self.layer3, \n",
    "                                       self.layer4, self.layer5, self.layer6)\n",
    "            \n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=256, out_features=128)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=32)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(32)\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(in_features=32, out_features=8)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(8)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(in_features=8, out_features=2)\n",
    "\n",
    "\n",
    "        self.lin = torch.nn.Sequential(self.fc1, self.bn1, self.fc2, self.bn2,\n",
    "                                       self.fc3, self.bn3, self.fc4)  \n",
    "\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = self.input_norm(X)\n",
    "        X = self.net(X)\n",
    "        X = X.reshape(X.size(0), -1)\n",
    "        X = self.lin(X)\n",
    "        X = torch.nn.functional.elu(X, alpha=1.0, inplace=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "AntiSpoofClassifier = Model(net, \"adam\", rmse, device)\n",
    "AntiSpoofClassifier.train(train_data=(data.train_inputs, data.train_outputs),\n",
    "                          val_data=(data.val_inputs, data.val_outputs),\n",
    "                          epochs=200, patience=20, batch_size=100, learning_rate=1.0E-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28603a003e0f3f16b61e11e8a1b17d48703271cacfa540e5bfac5b9de251aa54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
